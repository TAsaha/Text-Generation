{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s86f_PJsVU_"
      },
      "source": [
        "I'd be glad to guide you through creating a user interface (UI) for your text generative model. Here's a comprehensive approach that combines the best aspects of various methods and addresses potential considerations:\n",
        "\n",
        "**Choosing a Framework:**\n",
        "\n",
        "- **Web-Based UIs (Recommended):**\n",
        "    - **Gradio:** A user-friendly library for quickly building web interfaces for machine learning models. It offers pre-built components for text generation tasks, making it a great choice for beginners and prototyping ([https://gradio.app/](https://gradio.app/)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dCRS6_oyhx7",
        "outputId": "5f19cafd-7907-4174-af92-8bd88cd0731a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YnGic9a2386",
        "outputId": "ccbc8a48-fa31-4c39-9e47-78ce4cdb8220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcxygmTs21q3",
        "outputId": "22b00306-55a7-4ba6-975f-4e71540e6c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk4_6FnC21gs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UElmSyGTy4aG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0317c647-58ad-4a2a-96d8-7feec89a2888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk7H6lztyhpm",
        "outputId": "39c0f713-833c-48b4-dba6-aeead83218a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.221.58.132\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSSNNC5q1FOu",
        "outputId": "b74d3c4d-21b8-415c-d562-0f8df1e0fc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.221.58.132:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.892s\n",
            "your url is: https://shiny-seas-arrive.loca.lt\n",
            "2024-03-13 04:11:47.295766: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-13 04:11:47.295846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-13 04:11:47.297750: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-13 04:11:48.596445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-03-13 04:20:31.351 Uncaught app exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 542, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 7, in <module>\n",
            "    st.img(\"feenix-lab-logo_use-on-black.png\")\n",
            "AttributeError: module 'streamlit' has no attribute 'img'\n",
            "2024-03-13 04:21:55.593 Uncaught app exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/elements/image.py\", line 381, in image_to_url\n",
            "    with open(image, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'feenix-lab-logo_use-on-black.png'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 164, in _read_file\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'feenix-lab-logo_use-on-black.png'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 542, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 7, in <module>\n",
            "    st.image(\"feenix-lab-logo_use-on-black.png\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/metrics_util.py\", line 397, in wrapped_func\n",
            "    result = non_optional_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/elements/image.py\", line 161, in image\n",
            "    marshall_images(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/elements/image.py\", line 544, in marshall_images\n",
            "    proto_img.url = image_to_url(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/elements/image.py\", line 393, in image_to_url\n",
            "    url = runtime.get_instance().media_file_mgr.add(image, mimetype, image_id)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/media_file_manager.py\", line 224, in add\n",
            "    file_id = self._storage.load_and_get_id(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 115, in load_and_get_id\n",
            "    file_data = self._read_file(path_or_data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 167, in _read_file\n",
            "    raise MediaFileStorageError(f\"Error opening '{filename}'\") from ex\n",
            "streamlit.runtime.media_file_storage.MediaFileStorageError: Error opening 'feenix-lab-logo_use-on-black.png'\n",
            "2024-03-13 04:22:05.921 Uncaught app exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/elements/image.py\", line 381, in image_to_url\n",
            "    with open(image, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'feenix-lab-logo_use-on-black.png'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 164, in _read_file\n",
            "    with open(filename, \"rb\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'feenix-lab-logo_use-on-black.png'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 542, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 7, in <module>\n",
            "    st.image(\"feenix-lab-logo_use-on-black.png\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/metrics_util.py\", line 397, in wrapped_func\n",
            "    result = non_optional_func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/elements/image.py\", line 161, in image\n",
            "    marshall_images(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/elements/image.py\", line 544, in marshall_images\n",
            "    proto_img.url = image_to_url(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/elements/image.py\", line 393, in image_to_url\n",
            "    url = runtime.get_instance().media_file_mgr.add(image, mimetype, image_id)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/media_file_manager.py\", line 224, in add\n",
            "    file_id = self._storage.load_and_get_id(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 115, in load_and_get_id\n",
            "    file_data = self._read_file(path_or_data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/memory_media_file_storage.py\", line 167, in _read_file\n",
            "    raise MediaFileStorageError(f\"Error opening '{filename}'\") from ex\n",
            "streamlit.runtime.media_file_storage.MediaFileStorageError: Error opening 'feenix-lab-logo_use-on-black.png'\n",
            "config.json: 100% 1.01k/1.01k [00:00<00:00, 3.40MB/s]\n",
            "model.safetensors: 100% 526M/526M [00:04<00:00, 118MB/s]\n",
            "generation_config.json: 100% 119/119 [00:00<00:00, 448kB/s]\n",
            "tokenizer_config.json: 100% 727/727 [00:00<00:00, 2.76MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 58.0MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 123MB/s]\n",
            "tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 29.1MB/s]\n",
            "special_tokens_map.json: 100% 357/357 [00:00<00:00, 1.77MB/s]\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "config.json: 100% 1.35k/1.35k [00:00<00:00, 6.78MB/s]\n",
            "model.safetensors: 100% 5.31G/5.31G [00:51<00:00, 103MB/s]\n",
            "tokenizer_config.json: 100% 200/200 [00:00<00:00, 867kB/s]\n",
            "vocab.json: 100% 798k/798k [00:00<00:00, 34.6MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 45.5MB/s]\n",
            "special_tokens_map.json: 100% 90.0/90.0 [00:00<00:00, 463kB/s]\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}